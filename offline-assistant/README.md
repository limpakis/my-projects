# ğŸ§  Offline AI Assistant

An **offline-first AI assistant** with chat UI, retrieval-augmented generation (RAG), and local memory.  
Built using **FastAPI** (backend), **LangChain + Ollama** (LLM integration), **ChromaDB** (vector database), and a lightweight **HTML/JS frontend**.

## âœ¨ Features
- ğŸ—¨ï¸ Chat interface with adjustable parameters (temperature, max tokens, model)
- ğŸ“š RAG integration â€” augment answers with your own documents
- ğŸ’¾ Persistent memory across sessions (stored in SQLite via ChromaDB)
- ğŸ”Œ Runs completely **offline** (no external API calls required)
- ğŸŒ Web UI with local persistence (settings saved in browser)
- âš¡ Powered by **FastAPI + Uvicorn** for high-performance backend

## ğŸ› ï¸ Tech Stack
- **Backend:** FastAPI, Uvicorn, Requests
- **LLM Orchestration:** LangChain, langchain-ollama
- **Vector Store:** ChromaDB
- **Embeddings:** Sentence-Transformers
- **Document ingestion:** PyPDF
- **Data validation:** Pydantic
- **Frontend:** Vanilla HTML + CSS + JS

## ğŸ“‚ Project Structure
```
offline-assistant/
â”‚â”€â”€ app/
â”‚   â”œâ”€â”€ server.py         # FastAPI backend
â”‚   â”œâ”€â”€ rag_index.py      # RAG pipeline + document indexing
â”‚   â””â”€â”€ chroma_db/        # Local ChromaDB storage (SQLite)
â”‚â”€â”€ web/
â”‚   â””â”€â”€ index.html        # Chat UI
â”‚â”€â”€ docs/                 # Example documents
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ makefile              # Helper commands
â”‚â”€â”€ run.sh                # Startup script
```

## ğŸš€ Getting Started

### 1. Clone & Install
```bash
git clone https://github.com/your-username/offline-assistant.git
cd offline-assistant

# Create and activate venv
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Run Backend
```bash
uvicorn app.server:app --port 9000 --reload
```

### 3. Open Frontend
Simply open `web/index.html` in your browser.  
The UI will connect to the backend running at `http://localhost:9000`.

## ğŸ“¸ Demo
![Demo Screenshot](assets/example.png)

## ğŸŒ Deployment Notes
- Local use works out of the box.  
- If you want others to try it online:
  - You must deploy the **FastAPI backend** (e.g., Render, Railway, Fly.io, VPS).
  - Then update `index.html` to point to your deployed backend URL instead of `http://localhost:9000`.  
- GitHub Pages can only host the static `index.html`, not the backend.

## ğŸ“œ License
MIT â€” free to use and modify.
